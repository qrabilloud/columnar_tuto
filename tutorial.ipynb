{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Tutoriel : le paradigme columnar avec ClickHouse**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bienvenue dans notre tutoriel sur le moteur de base de données Clickhouse, basé sur le paradigme columnar. Ce tutoriel permet de présenter le paradigme columnar, d'étudier ses spécificités, ses atouts et ses limites. A cette fin, il vous est proposé de travailler sur un ensemble de données des taxis de la ville de New York. Vous allez manipuler ces données à la fois avec un moteur classique en MySQL et avec un moteur en columnar grâce à ClickHouse, avec pour objectif de faire la comparaison entre les deux approches pour mettre en valeur les singularités du paradigme columnar.\n",
    "\n",
    "Dans la majorité des bases de données relationelles, les données sont structurées et conservées sous forme de lignes. Pour chaque ligne il y a une clé primaire à laquelle sont associées des propriétés. Dans le cas du paradigme columnar, les données sont conservées sous forme de colonnes et non de lignes.\n",
    "Pour illustrer cette distinction entre les deux approches, ci-dessous un exemple tiré de notre jeu de données.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| ID    | Passenger Count  | Trip Distance  | Total amount  |\n",
    "| ----- | ---------------- | -------------- | ------------- |\n",
    "| 0     | 1                | 18             | 50            |\n",
    "| 1     | 2                | 3              | 8             |\n",
    "| 2     | 1                | 7              | 17            |\n",
    "| 3     | 4                | 10             | 32            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans une base de données orientée lignes, les données ci-dessus sont stockées selon les lignes :\n",
    "\n",
    "(0, 1, 18, 50) ; (1, 2, 3, 8) ; (2, 1, 7, 17) ; (3, 4, 10, 32).\n",
    "\n",
    "Tandis que dans une base de données columnar, la rétention se fait selon les colonnes :\n",
    "\n",
    "(0, 1, 2, 3) ; (1, 2, 1, 4) ; (18, 3, 7, 10) ; (50, 8, 17, 32)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Mise en place**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour commencer, il faut créer et démarrer les conteneurs encapsulant les différents composants nécessaires pour ce tutoriel, avec une commande `docker compose up`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite il faut se connecter au serveur Jupyter accessible à l'adresse http://localhost:8888."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin il faut configurer les connecteurs pour interagir avec les moteurs MySQL et ClickHouse. `conn` est le connecteur MySQL tandis que `client` est le client ClickHouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from utils import test_mysql, test_clickhouse, sql_query, conn, client\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Vérification des conteneurs**\n",
    "\n",
    "Exécutez les blocs ci-dessous pour valider la bonne connection avec les conteneurs de moteurs de base de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le résultat attendu est \"MySQL : (1, 'test', 100)\"\n",
    "test_mysql()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le résultat attendu est \"ClickHouse : (1, 'test', 100)\"\n",
    "test_clickhouse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargement du jeu de données avec les informations sur des trajets de taxi à New York.\n",
    "Le jeu de données a été réduit à 50 000 données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"./dataset/input_data.csv\",\n",
    "    usecols=[\n",
    "        \"VendorID\",\n",
    "        \"passenger_count\",\n",
    "        \"trip_distance\",\n",
    "        \"fare_amount\",\n",
    "        \"tip_amount\",\n",
    "        \"tolls_amount\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Découverte de la syntaxe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`client.command(query)` permet d'effectuer les opérations sur les tables (création, destruction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.command(\"DROP TABLE IF EXISTS dnd;\")\n",
    "client.command(\"\"\"\n",
    "    CREATE TABLE dnd (\n",
    "        id UInt32,\n",
    "        name VARCHAR(24),\n",
    "        age UInt8,\n",
    "        strengh Float32,\n",
    "        charisma Float32,\n",
    "        agility Float32,\n",
    "        intelligence Float32\n",
    "    ) ENGINE = MergeTree()\n",
    "    ORDER BY id;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`client.insert(table, data)` permet d'ajouter un ensemble de données à une table, où `data` prend la forme d'une liste de tuples représentant un tableau.\n",
    "\n",
    "`data = [(...), (...), ...]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    (1, \"Alice\", 23, 60, 80, 50, 55),\n",
    "    (2, \"Bob\", 24, 60, 75, 65, 45),\n",
    "    (3, \"Charlie\", 23, 90, 60, 45, 50),\n",
    "    (4, \"David\", 23, 70, 70, 55, 50),\n",
    "    (5, \"Eleanore\", 22, 60, 80, 40, 65),\n",
    "]\n",
    "client.insert(\"dnd\", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`client.query(query)` permet d'effectuer une requête pour obtenir des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = client.query(\"SELECT * FROM dnd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison 1 : Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_ROWS_TO_INSERT = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On charge `NB_ROWS_TO_INSERT` données une par une pour étudier le temps mis par chaque système pour les ajouter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MySQL\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"DROP TABLE IF EXISTS nyc_taxi;\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE nyc_taxi (\n",
    "        id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        vendor_id INT,\n",
    "        passenger_count INT,\n",
    "        trip_distance FLOAT,\n",
    "        fare_amount FLOAT,\n",
    "        tip_amount FLOAT,\n",
    "        tolls_amount FLOAT\n",
    "    );\n",
    "\"\"\")\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "t0_mysql = time.time()  # Start timing for MySQL\n",
    "for i, row in df.iterrows():\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO nyc_taxi (vendor_id, passenger_count, trip_distance, fare_amount, tip_amount, tolls_amount)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s)\n",
    "    \"\"\", tuple(row))\n",
    "    conn.commit()\n",
    "    if i == NB_ROWS_TO_INSERT:\n",
    "        break\n",
    "t1_mysql = time.time()  # End timing for MySQL\n",
    "mysql_time = t1_mysql - t0_mysql  # Compute execution time\n",
    "\n",
    "print(\"MySQL - Time required to add %d rows one by one : \" % (NB_ROWS_TO_INSERT), mysql_time)\n",
    "\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ClickHouse\n",
    "client.command(\"DROP TABLE IF EXISTS nyc_taxi;\")\n",
    "\n",
    "client.command(\"\"\"\n",
    "    CREATE TABLE nyc_taxi (\n",
    "        id UInt32,\n",
    "        vendor_id UInt8,\n",
    "        passenger_count UInt8,\n",
    "        trip_distance Float32,\n",
    "        fare_amount Float32,\n",
    "        tip_amount Float32,\n",
    "        tolls_amount Float32\n",
    "    ) ENGINE = MergeTree()\n",
    "    ORDER BY id;\n",
    "\"\"\")\n",
    "\n",
    "t0_clickhouse = time.time()  # Start timing for ClickHouse\n",
    "for i, row in df.iterrows():\n",
    "    client.insert(\"nyc_taxi\", [(i, row[\"VendorID\"], row[\"passenger_count\"], row[\"trip_distance\"], row[\"fare_amount\"], row[\"tip_amount\"], row[\"tolls_amount\"])])\n",
    "    if i == NB_ROWS_TO_INSERT:\n",
    "        break\n",
    "t1_clickhouse = time.time()  # End timing for ClickHouse\n",
    "clickhouse_time = t1_clickhouse - t0_clickhouse  # Compute execution time\n",
    "\n",
    "print(\"ClickHouse - Time required to add %d rows one by one : \" % (NB_ROWS_TO_INSERT), clickhouse_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "databases = [\"MySQL\", \"ClickHouse\"]\n",
    "times = [mysql_time, clickhouse_time]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(databases, times, color=['blue', 'red'], alpha=0.7)\n",
    "plt.ylabel(\"Insertion Time (seconds)\")\n",
    "plt.title(f\"Comparison of Data Insertion Time for {NB_ROWS_TO_INSERT} Rows\")\n",
    "plt.ylim(0, max(times) * 1.2)  # Adjust y-axis for visibility\n",
    "plt.text(0, mysql_time, f\"{mysql_time:.2f}s\", ha='center', va='bottom', fontsize=12)\n",
    "plt.text(1, clickhouse_time, f\"{clickhouse_time:.2f}s\", ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On observe que ClickHouse est beaucoup plus lent que MySQL pour l'insertion des données.\n",
    "Cela est dû à la différence dans la façon de conserver les données.\n",
    "- Pour MySQL, on ajoute 1 liste de N éléments\n",
    "- Pour ClickHouse, on ajoute 1 élement dans N listes\n",
    "\n",
    "Afin de pallier ce problème, on utilise la fonction `insert` avec un tableau de données pour ajouter un paquet plutôt que des données une par une."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajoutez à présent l'ensemble des données dans les deux bases de données (cela devrait prendre quelques minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MySQL\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"DROP TABLE IF EXISTS nyc_taxi;\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE nyc_taxi (\n",
    "        id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        vendor_id INT,\n",
    "        passenger_count INT,\n",
    "        trip_distance FLOAT,\n",
    "        fare_amount FLOAT,\n",
    "        tip_amount FLOAT,\n",
    "        tolls_amount FLOAT\n",
    "    );\n",
    "\"\"\")\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO nyc_taxi (vendor_id, passenger_count, trip_distance, fare_amount, tip_amount, tolls_amount)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s)\n",
    "    \"\"\", tuple(row))\n",
    "\n",
    "conn.commit()\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ClickHouse\n",
    "client.command(\"DROP TABLE IF EXISTS nyc_taxi;\")\n",
    "\n",
    "client.command(\"\"\"\n",
    "    CREATE TABLE nyc_taxi (\n",
    "        id UInt32,\n",
    "        vendor_id UInt8,\n",
    "        passenger_count UInt8,\n",
    "        trip_distance Float32,\n",
    "        fare_amount Float32,\n",
    "        tip_amount Float32,\n",
    "        tolls_amount Float32\n",
    "    ) ENGINE = MergeTree()\n",
    "    ORDER BY id;\n",
    "\"\"\")\n",
    "\n",
    "data = []\n",
    "for i, row in df.iterrows():\n",
    "    data.append([i, row[\"VendorID\"], row[\"passenger_count\"], row[\"trip_distance\"], row[\"fare_amount\"], row[\"tip_amount\"], row[\"tolls_amount\"]])\n",
    "\n",
    "client.insert(\"nyc_taxi\", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit ici qu'il y a un réel gain de temps lors de l'ajout par paquet.\n",
    "L'ajout progressif des données est une limitation importante de ClickHouse et des bases de données orientées colonnes en général."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifiez que les deux bases de données contiennent bien le même nombre de lignes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sql_query(\"SELECT COUNT(*) FROM nyc_taxi;\")\n",
    "print(\"MySQL Total Rows:\", result[0][0])\n",
    "\n",
    "result = client.query(\"SELECT COUNT(*) FROM nyc_taxi;\")\n",
    "print(\"ClickHouse Total Rows:\", result.result_rows[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison 2 : Requêtes globales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On construit un jeu de requêtes pour étudier la différence dans le temps d'execution des requêtes selon la base de données. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_A = \"SELECT * FROM nyc_taxi;\"\n",
    "query_B = \"SELECT * FROM nyc_taxi ORDER BY passenger_count ASC, fare_amount DESC;\"\n",
    "query_C = \"SELECT SUM(trip_distance) FROM nyc_taxi;\"\n",
    "query_D = \"SELECT COUNT(*) FROM nyc_taxi;\"\n",
    "query_E = \"SELECT COUNT(passenger_count) FROM nyc_taxi;\"\n",
    "\n",
    "queries = [query_A, query_B, query_C, query_D, query_E]\n",
    "query_labels = [\"SELECT *\", \"ORDER BY\", \"SUM\", \"COUNT\", \"COUNT column\"]\n",
    "iterations = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mysql_times = []\n",
    "clickhouse_times = []\n",
    "\n",
    "for query in queries:\n",
    "    # Measure MySQL query execution time\n",
    "    t0_mysql = time.time()\n",
    "    for _ in range(iterations):\n",
    "        resultsql = sql_query(query)\n",
    "    t1_mysql = time.time()\n",
    "    mysql_time = (t1_mysql - t0_mysql) / iterations  # Average time per query\n",
    "\n",
    "    # Measure ClickHouse query execution time\n",
    "    t0_clickhouse = time.time()\n",
    "    for _ in range(iterations):\n",
    "        resultcol = client.query(query)\n",
    "    t1_clickhouse = time.time()\n",
    "    clickhouse_time = (t1_clickhouse - t0_clickhouse) / iterations  # Average time per query\n",
    "\n",
    "    # Store times for visualization\n",
    "    mysql_times.append(mysql_time)\n",
    "    clickhouse_times.append(clickhouse_time)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"MySQL Time:      {mysql_time:.5f} seconds\")\n",
    "    print(f\"ClickHouse Time: {clickhouse_time:.5f} seconds\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(query_labels))  # Label positions\n",
    "width = 0.35  # Width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars1 = ax.bar(x - width/2, mysql_times, width, label='MySQL', color='blue', alpha=0.7)\n",
    "bars2 = ax.bar(x + width/2, clickhouse_times, width, label='ClickHouse', color='red', alpha=0.7)\n",
    "\n",
    "ax.set_ylabel('Query Execution Time (seconds)')\n",
    "ax.set_title('Query Performance: MySQL vs ClickHouse')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(query_labels, rotation=20, ha=\"right\")\n",
    "ax.legend()\n",
    "\n",
    "# Annotate bars with values\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    ax.annotate(f'{height:.4f}s', xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3), textcoords=\"offset points\", ha='center', fontsize=10)\n",
    "\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    ax.annotate(f'{height:.4f}s', xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3), textcoords=\"offset points\", ha='center', fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate que pour des requêtes globales, notamment les agrégations, ClickHouse est plus performant que MySQL. En effet, le paradigme columnar est particulièrement efficace pour traiter des requêtes ne nécessitant qu'un faible nombre de colonnes et faisant appel à des agrégations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À présent à vous d'essayer de faire une requête pour comparer les performances des deux paradigmes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM nyc_taxi;\"\n",
    "iterations = 25\n",
    "t0 = time.time()\n",
    "for i in range(iterations) :\n",
    "    resultsql = sql_query(query)\n",
    "t1 = time.time()\n",
    "for i in range(iterations) :\n",
    "    resultcol = client.query(query)\n",
    "t2 = time.time()\n",
    "print(\"Requête : \", query)\n",
    "print(\"MySQL :      \", (t1 - t0)/iterations)\n",
    "print(\"ClickHouse : \", (t2 - t1)/iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison 3 : Requêtes spécifiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On étudie à présent le cas où l'on souhaite accéder à une ligne spécifique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = \"SELECT * FROM nyc_taxi WHERE id=1523\"\n",
    "iterations = 25\n",
    "\n",
    "t0_mysql_1 = time.time()\n",
    "for _ in range(iterations):\n",
    "    resultsql = sql_query(query1)\n",
    "t1_mysql_1 = time.time()\n",
    "mysql_time_1 = (t1_mysql_1 - t0_mysql_1) / iterations\n",
    "\n",
    "t0_clickhouse_1 = time.time()\n",
    "for _ in range(iterations):\n",
    "    resultcol = client.query(query1)\n",
    "t1_clickhouse_1 = time.time()\n",
    "clickhouse_time_1 = (t1_clickhouse_1 - t0_clickhouse_1) / iterations\n",
    "\n",
    "print(f\"Query 1 - MySQL Time: {mysql_time_1:.5f} seconds\")\n",
    "print(f\"Query 1 - ClickHouse Time: {clickhouse_time_1:.5f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query2 = \"SELECT * FROM nyc_taxi WHERE id=30523 OR id=28645\"\n",
    "iterations = 25\n",
    "\n",
    "t0_mysql_2 = time.time()\n",
    "for _ in range(iterations):\n",
    "    resultsql = sql_query(query2)\n",
    "t1_mysql_2 = time.time()\n",
    "mysql_time_2 = (t1_mysql_2 - t0_mysql_2) / iterations\n",
    "\n",
    "t0_clickhouse_2 = time.time()\n",
    "for _ in range(iterations):\n",
    "    resultcol = client.query(query2)\n",
    "t1_clickhouse_2 = time.time()\n",
    "clickhouse_time_2 = (t1_clickhouse_2 - t0_clickhouse_2) / iterations\n",
    "\n",
    "print(f\"Query 2 - MySQL Time: {mysql_time_2:.5f} seconds\")\n",
    "print(f\"Query 2 - ClickHouse Time: {clickhouse_time_2:.5f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les accès de lignes précises sont bien plus longues avec ClickHouse qu'avec MySQL !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query3 = \"SELECT * FROM nyc_taxi WHERE id = 30523 OR tip_amount > 0\"\n",
    "iterations = 25\n",
    "\n",
    "t0_mysql_3 = time.time()\n",
    "for _ in range(iterations):\n",
    "    resultsql = sql_query(query3)\n",
    "t1_mysql_3 = time.time()\n",
    "mysql_time_3 = (t1_mysql_3 - t0_mysql_3) / iterations\n",
    "\n",
    "t0_clickhouse_3 = time.time()\n",
    "for _ in range(iterations):\n",
    "    resultcol = client.query(query3)\n",
    "t1_clickhouse_3 = time.time()\n",
    "clickhouse_time_3 = (t1_clickhouse_3 - t0_clickhouse_3) / iterations\n",
    "\n",
    "print(f\"Query 3 - MySQL Time: {mysql_time_3:.5f} seconds\")\n",
    "print(f\"Query 3 - ClickHouse Time: {clickhouse_time_3:.5f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query4 = \"SELECT * FROM nyc_taxi WHERE fare_amount > 1 AND fare_amount < 12\"\n",
    "iterations = 25\n",
    "\n",
    "t0_mysql_4 = time.time()\n",
    "for _ in range(iterations):\n",
    "    resultsql = sql_query(query4)\n",
    "t1_mysql_4 = time.time()\n",
    "mysql_time_4 = (t1_mysql_4 - t0_mysql_4) / iterations\n",
    "\n",
    "t0_clickhouse_4 = time.time()\n",
    "for _ in range(iterations):\n",
    "    resultcol = client.query(query4)\n",
    "t1_clickhouse_4 = time.time()\n",
    "clickhouse_time_4 = (t1_clickhouse_4 - t0_clickhouse_4) / iterations\n",
    "\n",
    "print(f\"Query 4 - MySQL Time: {mysql_time_4:.5f} seconds\")\n",
    "print(f\"Query 4 - ClickHouse Time: {clickhouse_time_4:.5f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A l'inverse, le filtrage concernant une colonne est bien plus rapide avec ClickHouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query5 = \"SELECT * FROM nyc_taxi WHERE fare_amount = 1.0\"\n",
    "iterations = 25\n",
    "\n",
    "t0_mysql_5 = time.time()\n",
    "for _ in range(iterations):\n",
    "    resultsql = sql_query(query5)\n",
    "t1_mysql_5 = time.time()\n",
    "mysql_time_5 = (t1_mysql_5 - t0_mysql_5) / iterations\n",
    "\n",
    "t0_clickhouse_5 = time.time()\n",
    "for _ in range(iterations):\n",
    "    resultcol = client.query(query5)\n",
    "t1_clickhouse_5 = time.time()\n",
    "clickhouse_time_5 = (t1_clickhouse_5 - t0_clickhouse_5) / iterations\n",
    "\n",
    "print(f\"Query 5 - MySQL Time: {mysql_time_5:.5f} seconds\")\n",
    "print(f\"Query 5 - ClickHouse Time: {clickhouse_time_5:.5f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script 6: Visualization of Query Performance for All 5 Queries\n",
    "query_labels = [\"Query 1\", \"Query 2\", \"Query 3\", \"Query 4\", \"Query 5\"]\n",
    "mysql_times = [mysql_time_1, mysql_time_2, mysql_time_3, mysql_time_4, mysql_time_5]\n",
    "clickhouse_times = [clickhouse_time_1, clickhouse_time_2, clickhouse_time_3, clickhouse_time_4, clickhouse_time_5]\n",
    "\n",
    "x = np.arange(len(query_labels))  # Label positions\n",
    "width = 0.35  # Bar width\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars1 = ax.bar(x - width/2, mysql_times, width, label='MySQL', color='blue', alpha=0.7)\n",
    "bars2 = ax.bar(x + width/2, clickhouse_times, width, label='ClickHouse', color='red', alpha=0.7)\n",
    "\n",
    "ax.set_ylabel('Query Execution Time (seconds)')\n",
    "ax.set_title('Performance Comparison: MySQL vs ClickHouse')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(query_labels)\n",
    "ax.legend()\n",
    "\n",
    "# Annotate bars with values\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    ax.annotate(f'{height:.5f}s', xy=(bar.get_x() + bar.get_width()/2, height),\n",
    "                xytext=(0, 3), textcoords=\"offset points\", ha='center', fontsize=10)\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    ax.annotate(f'{height:.5f}s', xy=(bar.get_x() + bar.get_width()/2, height),\n",
    "                xytext=(0, 3), textcoords=\"offset points\", ha='center', fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison 4 : Requête avec jointure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(1, 0, 0.0),\n",
    "        (2, 1, 1.0),\n",
    "        (3, 2, 3.5),\n",
    "        (5, 3, 6.0),\n",
    "        (8, 4, 10.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"DROP TABLE IF EXISTS special_rule;\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE special_rule (\n",
    "        id INT PRIMARY KEY,\n",
    "        passenger INT,\n",
    "        reduction FLOAT\n",
    "    );\n",
    "\"\"\")\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "for row in data:\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO special_rule (id, passenger, reduction)\n",
    "        VALUES (%s, %s, %s)\n",
    "    \"\"\", row)\n",
    "\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "\n",
    "client.command(\"DROP TABLE IF EXISTS special_rule;\")\n",
    "\n",
    "client.command(\"\"\"\n",
    "    CREATE TABLE special_rule (\n",
    "        id UInt32,\n",
    "        passenger UInt8,\n",
    "        reduction Float32\n",
    "    ) ENGINE = MergeTree()\n",
    "    ORDER BY id;\n",
    "\"\"\")\n",
    "\n",
    "client.insert(\"special_rule\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsql = sql_query(\"SELECT * FROM special_rule\")\n",
    "print(resultsql)\n",
    "resultcol = client.query(\"SELECT * FROM special_rule\")\n",
    "print(resultcol.result_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_join = \"SELECT * FROM nyc_taxi JOIN special_rule ON nyc_taxi.passenger_count = special_rule.passenger WHERE tip_amount < 10 * fare_amount\"\n",
    "iterations = 25\n",
    "\n",
    "t0_mysql_join = time.time()\n",
    "for _ in range(iterations):\n",
    "    resultsql = sql_query(query_join)\n",
    "t1_mysql_join = time.time()\n",
    "mysql_join_time = (t1_mysql_join - t0_mysql_join) / iterations\n",
    "\n",
    "t0_clickhouse_join = time.time()\n",
    "for _ in range(iterations):\n",
    "    resultcol = client.query(query_join)\n",
    "t1_clickhouse_join = time.time()\n",
    "clickhouse_join_time = (t1_clickhouse_join - t0_clickhouse_join) / iterations\n",
    "\n",
    "print(\"Join Query - MySQL Time:      {:.5f} seconds\".format(mysql_join_time))\n",
    "print(\"Join Query - ClickHouse Time: {:.5f} seconds\".format(clickhouse_join_time))\n",
    "\n",
    "databases = [\"MySQL\", \"ClickHouse\"]\n",
    "times_join = [mysql_join_time, clickhouse_join_time]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(databases, times_join, color=['blue', 'red'], alpha=0.7)\n",
    "plt.ylabel(\"Average Execution Time (seconds)\")\n",
    "plt.title(\"Join Query Performance: MySQL vs ClickHouse\")\n",
    "plt.ylim(0, max(times_join) * 1.2)\n",
    "plt.text(0, mysql_join_time, f\"{mysql_join_time:.5f}s\", ha='center', va='bottom', fontsize=12)\n",
    "plt.text(1, clickhouse_join_time, f\"{clickhouse_join_time:.5f}s\", ha='center', va='bottom', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En conclusion, le columnar est plus pertinent pour les données analytiques ou historiques (informatique décisionnelle) qui ont besoin d'être lues rapidement et en grands volumes, qui sont peu modifiées ou agrégées. Ce paradigme est également recommandé pour les requêtes impliquant un nombre limité de colonnes ou un grand nombre de lignes. Enfin cela permet un requêtage plus performant, un meilleur taux de compression et de partition des données.\n",
    "\n",
    "À l'inverse, pour des bases de données transactionnelles, avec de nombreux ajouts et mises à jour de données avec une grande variabilité et de multiples colonnes, le columnar est peu approprié et présente des performances décevantes voire rédhibitoires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour tirer profit au maximum des atouts de chaque paradigme, en ligne ou en colonne, il est possible d'hybrider les technologies, comme c'est le cas sur les projets Snowflake ou Google Big Query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparaison Finale : MySQL vs. ClickHouse\n",
    "\n",
    "Après avoir testé **l'insertion, les filtres, les agrégations et les jointures**, voici un récapitulatif des **points forts et des limites de ClickHouse** par rapport à MySQL.\n",
    "\n",
    "---\n",
    "\n",
    "## Comparaison des Performances\n",
    "\n",
    "| **Critère** | **ClickHouse** | **MySQL** | **Explication** |\n",
    "|------------|--------------|-----------|------------------------------------------------|\n",
    "| **Insertion ligne par ligne** | ❌ Lent | ✅ Rapide | MySQL est optimisé pour les transactions fréquentes |\n",
    "| **Insertion en lot** | ✅ Rapide | ❌ Plus lent | ClickHouse optimise les insertions groupées |\n",
    "| **Requêtes d'agrégation (`SUM`, `COUNT`)** | ✅ Rapide | ❌ Plus lent | Lecture ciblée des colonnes avec moins d'I/O disque |\n",
    "| **Filtrage (`WHERE x > y`)** | ✅ Rapide | ❌ Plus lent | ClickHouse ne lit que les colonnes nécessaires |\n",
    "| **Lecture de gros volumes** | ✅ Rapide | ❌ Plus lent | Stockage en colonnes et compression efficace |\n",
    "| **Requêtes sur une ligne (`id = X`)** | ❌ Lent | ✅ Rapide | MySQL indexe mieux les accès directs |\n",
    "| **Jointures complexes** | ❌ Lent | ✅ Plus rapide | MySQL gère mieux les relations entre tables |\n",
    "| **Mises à jour (`UPDATE`, `DELETE`)** | ❌ Mauvais | ✅ Adapté | ClickHouse est conçu pour de l'append-only |\n",
    "\n",
    "---\n",
    "\n",
    "## Quand utiliser ClickHouse ?\n",
    "✅ **Idéal pour** :\n",
    "- Analyses **Big Data**, **BI**, et tableaux de bord  \n",
    "- Stockage de **logs**, **monitoring**, et analyse temps réel  \n",
    "- Requêtes sur **très grandes tables** (millions de lignes)  \n",
    "\n",
    "❌ **À éviter pour** :\n",
    "- Bases de données **transactionnelles** (e-commerce, finance)  \n",
    "- **Mises à jour fréquentes** et relations complexes  \n",
    "- Petites bases avec des **requêtes simples**  \n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "- **Si vous avez besoin d'un moteur rapide pour l'analyse de données**, utilisez **ClickHouse**.  \n",
    "- **Si votre base est transactionnelle avec de nombreuses écritures et mises à jour**, préférez **MySQL**.  \n",
    "\n",
    "**Bon compromis** : utiliser **MySQL pour les transactions** et **ClickHouse pour l'analytics**.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
